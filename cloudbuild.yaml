steps:
  # 0. Docker Build
  - name: gcr.io/cloud-builders/docker
    args:
      - build
      - '--no-cache'
      - '-t'
      - '$_AR_HOSTNAME/$PROJECT_ID/$REPO_NAME/$_SERVICE_NAME:$COMMIT_SHA'
      - .
      - '-f'
      - Dockerfile
    id: Build

  # 1. Docker push to Google Artifact Registry
  - name: gcr.io/cloud-builders/docker
    args:
      - push
      - '$_AR_HOSTNAME/$PROJECT_ID/$REPO_NAME/$_SERVICE_NAME:$COMMIT_SHA'
    id: Push

  # 2. Check Cloud SQL connectivity
  - name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: 'sh'
    args:
      - '-c'
      - |
        gcloud sql instances describe ${_DB_INSTANCE} --format='value(ipAddresses.ipAddress)'
    id: ping db


  # 3. Create a Dajngo superuser
  - name: 'gcr.io/google-appengine/exec-wrapper'
    args:
      - '-i'
      - '$_AR_HOSTNAME/$PROJECT_ID/$REPO_NAME/$_SERVICE_NAME:$COMMIT_SHA'
      - '-s'
      - '${PROJECT_ID}:${_DEPLOY_REGION}:${_DB_INSTANCE}'
      - '-e'
      - 'DJANGO_SUPERUSER_USERNAME=${_DJANGO_SUPERUSER_USERNAME}'
      - '-e'
      - 'DJANGO_SUPERUSER_EMAIL=${_DJANGO_SUPERUSER_EMAIL}'
      - '-e'
      - 'DJANGO_SUPERUSER_PASSWORD=${_DJANGO_SUPERUSER_PASSWORD}'
      - '--'
      - 'sh'
      - '-c'
      - |
        python manage.py makesuperuser ${DJANGO_SUPERUSER_USERNAME} ${DJANGO_SUPERUSER_EMAIL} ${DJANGO_SUPERUSER_PASSWORD} &&
        echo "Superuser created successfully"
    id: Create superuser

  # 4. Create a new migration
  - name: gcr.io/google-appengine/exec-wrapper
    args:
      - '-i'
      - '$_AR_HOSTNAME/$PROJECT_ID/$REPO_NAME/$_SERVICE_NAME:$COMMIT_SHA'
      - '-s'
      - '${PROJECT_ID}:${_DEPLOY_REGION}:${_DB_INSTANCE}'
      - '-e'
      - 'SETTINGS_NAME=${_SECRET_SETTINGS_NAME}'
      - '--'
      - 'python'
      - 'manage.py'
      - 'migrate'
    id: Create migrations

  # 5. Collect static
  - name: gcr.io/google-appengine/exec-wrapper
    args:
      - '-i'
      - '$_AR_HOSTNAME/$PROJECT_ID/$REPO_NAME/$_SERVICE_NAME:$COMMIT_SHA'
      - '-s'
      - '${PROJECT_ID}:${_DEPLOY_REGION}:${_DB_INSTANCE}'
      - '-e'
      - 'SETTINGS_NAME=${_SECRET_SETTINGS_NAME}'
      - '--'
      - 'python'
      - 'manage.py'
      - 'collectstatic'
      - '--no-input'
    id: Collect static


  # 6. Deploy to Cloud Run
  - name: gcr.io/google.com/cloudsdktool/cloud-sdk:slim
    args:
      - run
      - services
      - update
      - $_SERVICE_NAME
      - '--platform=managed'
      - '--image=$_AR_HOSTNAME/$PROJECT_ID/$REPO_NAME/$_SERVICE_NAME:$COMMIT_SHA'
      - >-
        --labels=managed-by=gcp-cloud-build-deploy-cloud-run,commit-sha=$COMMIT_SHA,gcb-build-id=$BUILD_ID,gcb-trigger-id=$_TRIGGER_ID,$_LABELS
      - '--region=$_DEPLOY_REGION'
      - '--quiet'
    id: Deploy
    entrypoint: gcloud

  # 7. Step to print contents of migrations directory to check migrations
  - name: 'gcr.io/google-appengine/exec-wrapper'
    args:
      - '-i'
      - '$_AR_HOSTNAME/$PROJECT_ID/$REPO_NAME/$_SERVICE_NAME:$COMMIT_SHA'
      - '-s'
      - '${PROJECT_ID}:${_DEPLOY_REGION}:${_DB_INSTANCE}'
      - '-e'
      - 'SETTINGS_NAME=${_SECRET_SETTINGS_NAME}'
      - '--'
      - 'sh'
      - '-c'
      - |
        echo "Contents of migrations directory:"
        ls -la /workspace/kp_app/migrations/
        echo "\nContent of each migration file:"
        for file in /workspace/kp_app/migrations/*.py; do
          if [ -f "$file" ]; then
            echo "\n--- $file ---"
            cat "$file"
          fi
        done
    id: Print migrations dir


# Store images in Google Artifact Registry
images:
  - '$_AR_HOSTNAME/$PROJECT_ID/$REPO_NAME/$_SERVICE_NAME:$COMMIT_SHA'

# define where logs should be stored
# you can also have them sent to a bucket
options:
  logging: CLOUD_LOGGING_ONLY

tags:
  - gcp-cloud-build-deploy-cloud-run
  - gcp-cloud-build-deploy-cloud-run-managed
  - kp-run
